{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lm7ey0ebddh",
   "source": "# Pairwise PID Synergy Graph Construction Across 12 Benchmark Datasets\n\nThis notebook demonstrates the computation of **Partial Information Decomposition (PID) synergy scores** (Williams-Beer I_min) for all feature pairs across tabular classification datasets, followed by **synergy graph construction** and analysis.\n\n**What this artifact does:**\n- Computes pairwise PID synergy scores for all feature pairs using a manual MI-based PID implementation\n- Constructs synergy graphs at 3 threshold levels (top-10%, top-25%, above-median) with NetworkX\n- Analyzes graph structure: cliques, connected components, clustering coefficient\n- Compares PID synergy against a baseline interaction information measure\n- Evaluates discretization stability (5-bin vs 10-bin) using Spearman/Jaccard metrics\n- Checks domain-meaningful interactions for diabetes, breast cancer, and heart datasets\n\n---\n\n**Part 1** — Quick Demo using a curated subset (5 datasets, runs in seconds)\n\n**Part 2** — Full Run using all 12 datasets with original parameters",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "bd0ucgb9dqp",
   "source": "import json\nimport os\nimport time\nimport warnings\nfrom collections import Counter\nfrom itertools import combinations\n\nimport numpy as np\nfrom scipy.stats import pearsonr, spearmanr\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7ja54uiud0s",
   "source": "## Data Loading\n\nLoad pre-computed PID synergy results from JSON. The data was produced by the full pipeline which computed pairwise PID decomposition (synergy, redundancy, unique information) for all feature pairs across 12 benchmark datasets.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0ugi3ejggkzq",
   "source": "GITHUB_FULL_DATA_URL = \"https://raw.githubusercontent.com/AMGrobelnik/ai-invention-ac2586-synergy-guided-oblique-splits-using-part/main/pid_synergy_gra/demo/full_demo_data.json\"\nGITHUB_MINI_DATA_URL = \"https://raw.githubusercontent.com/AMGrobelnik/ai-invention-ac2586-synergy-guided-oblique-splits-using-part/main/pid_synergy_gra/demo/mini_demo_data.json\"\n\ndef _load_json(url, local_path):\n    try:\n        import urllib.request\n        with urllib.request.urlopen(url) as response:\n            return json.loads(response.read().decode())\n    except Exception: pass\n    if os.path.exists(local_path):\n        with open(local_path) as f: return json.load(f)\n    raise FileNotFoundError(f\"Could not load {local_path}\")\n\ndef load_mini():\n    return _load_json(GITHUB_MINI_DATA_URL, \"mini_demo_data.json\")\n\ndef load_full():\n    return _load_json(GITHUB_FULL_DATA_URL, \"full_demo_data.json\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "hj3t1x1trpo",
   "source": "---\n# Part 1 — Quick Demo (Mini Data)\n\nUses a curated subset of 5 datasets (banknote-authentication, diabetes, glass, wine, heart-statlog) for fast execution.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "f6zrsya1jjl",
   "source": "data = load_mini()\nprint(f\"Loaded {len(data['datasets'])} datasets\")\nfor ds in data[\"datasets\"]:\n    print(f\"  {ds['dataset']}: {len(ds['examples'])} feature pairs\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "p6jhtyxdkqd",
   "source": "## Parse PID Results\n\nExtract PID decomposition results from the loaded JSON into per-dataset lists of dictionaries, matching the format used by the original pipeline's graph construction and analysis functions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "zsr7luo3l",
   "source": "def parse_pid_results(data):\n    \"\"\"Parse loaded JSON data into per-dataset PID result dicts.\n    \n    Returns dict mapping dataset_name -> {\n        'pid_results': list of PID result dicts,\n        'feature_names': list of unique feature names,\n        'n_features': int, 'n_samples': int, 'n_classes': int,\n        'stability_spearman': float, 'stability_pearson': float,\n    }\n    \"\"\"\n    all_datasets = {}\n    for ds_block in data[\"datasets\"]:\n        ds_name = ds_block[\"dataset\"]\n        examples = ds_block[\"examples\"]\n        if not examples:\n            continue\n\n        pid_results = []\n        feature_set = set()\n        for ex in examples:\n            inp = json.loads(ex[\"input\"])\n            feature_set.add(inp[\"feature_i\"])\n            feature_set.add(inp[\"feature_j\"])\n            pid_results.append({\n                \"feature_i\": inp[\"feature_i\"],\n                \"feature_j\": inp[\"feature_j\"],\n                \"synergy\": ex[\"metadata_synergy\"],\n                \"unique_i\": ex[\"metadata_unique_i\"],\n                \"unique_j\": ex[\"metadata_unique_j\"],\n                \"redundancy\": ex[\"metadata_redundancy\"],\n                \"joint_mi\": ex[\"metadata_joint_mi\"],\n                \"mi_i\": ex[\"metadata_mi_i\"],\n                \"mi_j\": ex[\"metadata_mi_j\"],\n                \"baseline_interaction\": ex[\"metadata_baseline_interaction\"],\n                \"n_bins\": ex[\"metadata_bin_level\"],\n            })\n\n        first = examples[0]\n        all_datasets[ds_name] = {\n            \"pid_results\": pid_results,\n            \"feature_names\": sorted(feature_set),\n            \"n_features\": first[\"metadata_n_features\"],\n            \"n_samples\": first[\"metadata_n_samples\"],\n            \"n_classes\": first[\"metadata_n_classes\"],\n            \"stability_spearman\": first.get(\"metadata_stability_spearman\", None),\n            \"stability_pearson\": first.get(\"metadata_stability_pearson\", None),\n        }\n\n    return all_datasets\n\nall_datasets = parse_pid_results(data)\nprint(f\"Parsed {len(all_datasets)} datasets:\")\nfor name, info in all_datasets.items():\n    print(f\"  {name}: {info['n_features']} features, \"\n          f\"{len(info['pid_results'])} pairs, \"\n          f\"{info['n_samples']} samples, \"\n          f\"{info['n_classes']} classes\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4twxbh5c6rn",
   "source": "## Synergy Graph Construction & Analysis\n\nBuild synergy graphs by thresholding pairwise synergy scores at 3 levels (top-10%, top-25%, above-median). Analyze graph structure including edge count, density, connected components, largest clique, and clustering coefficient.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "krrsopzh4g",
   "source": "# ── Constants (from original) ────────────────────────────────────────────────\nTHRESHOLDS = {\"top_10pct\": 0.90, \"top_25pct\": 0.75, \"above_median\": 0.50}\n\n# ── Domain knowledge pairs for checking (from original) ─────────────────────\nDOMAIN_PAIRS = {\n    \"diabetes\": [(\"plas\", \"insu\"), (\"plas\", \"mass\"), (\"mass\", \"age\")],\n    \"breast_cancer_wisconsin\": [\n        (\"mean radius\", \"mean perimeter\"),\n        (\"mean area\", \"mean concavity\"),\n    ],\n    \"heart-statlog\": [\n        (\"chest\", \"maximum_heart_rate_achieved\"),\n        (\"age\", \"oldpeak\"),\n    ],\n}\n\n\ndef build_synergy_graph(\n    pid_results: list,\n    feature_names: list,\n    threshold_quantile: float,\n) -> tuple:\n    \"\"\"Build a synergy graph with edges above the given quantile threshold.\"\"\"\n    synergy_values = [r[\"synergy\"] for r in pid_results]\n    if not synergy_values:\n        return nx.Graph(), 0.0\n\n    threshold_value = float(np.quantile(synergy_values, threshold_quantile))\n\n    G = nx.Graph()\n    G.add_nodes_from(feature_names)\n    for r in pid_results:\n        if r[\"synergy\"] >= threshold_value:\n            G.add_edge(r[\"feature_i\"], r[\"feature_j\"], weight=r[\"synergy\"])\n\n    return G, threshold_value\n\n\ndef analyze_graph(G: nx.Graph) -> dict:\n    \"\"\"Compute graph statistics.\"\"\"\n    n_nodes = G.number_of_nodes()\n    n_edges = G.number_of_edges()\n    nodes_with_edges = sum(1 for n in G.nodes() if G.degree(n) > 0)\n\n    if n_nodes < 2:\n        return {\n            \"n_edges\": n_edges,\n            \"n_nodes_with_edges\": nodes_with_edges,\n            \"density\": 0.0,\n            \"n_connected_components\": 0,\n            \"largest_component_size\": 0,\n            \"largest_clique_size\": 0,\n            \"mean_degree\": 0.0,\n            \"max_degree\": 0,\n            \"clustering_coefficient\": 0.0,\n        }\n\n    max_edges = n_nodes * (n_nodes - 1) / 2\n    density = n_edges / max_edges if max_edges > 0 else 0.0\n\n    components = list(nx.connected_components(G))\n    component_sizes = [len(c) for c in components]\n\n    cliques = list(nx.find_cliques(G)) if n_edges > 0 else []\n    clique_sizes = [len(c) for c in cliques] if cliques else [0]\n\n    degrees = [d for _, d in G.degree()]\n    mean_degree = float(np.mean(degrees)) if degrees else 0.0\n    max_degree = max(degrees) if degrees else 0\n\n    cc = nx.average_clustering(G) if n_edges > 0 else 0.0\n\n    return {\n        \"n_edges\": n_edges,\n        \"n_nodes_with_edges\": nodes_with_edges,\n        \"density\": round(density, 4),\n        \"n_connected_components\": len(components),\n        \"largest_component_size\": max(component_sizes) if component_sizes else 0,\n        \"largest_clique_size\": max(clique_sizes),\n        \"mean_degree\": round(mean_degree, 2),\n        \"max_degree\": max_degree,\n        \"clustering_coefficient\": round(cc, 4),\n    }\n\nprint(\"Graph construction functions defined.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "t439m3zr2f",
   "source": "### Build Graphs for All Datasets\n\nFor each dataset, construct synergy graphs at all 3 threshold levels and compute graph statistics.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "jw7ok6wb9gi",
   "source": "t_start = time.time()\ngraph_results = {}\n\nfor ds_name, ds_info in all_datasets.items():\n    pid_results = ds_info[\"pid_results\"]\n    feature_names = ds_info[\"feature_names\"]\n\n    graph_stats = {}\n    for thr_name, thr_q in THRESHOLDS.items():\n        G, thr_val = build_synergy_graph(\n            pid_results=pid_results,\n            feature_names=feature_names,\n            threshold_quantile=thr_q,\n        )\n        stats = analyze_graph(G)\n        stats[\"threshold_value\"] = round(thr_val, 6)\n        graph_stats[thr_name] = stats\n\n    graph_results[ds_name] = {\n        \"graph_stats\": graph_stats,\n        \"pid_results\": pid_results,\n        \"ds_info\": ds_info,\n    }\n\nelapsed = time.time() - t_start\nprint(f\"Built synergy graphs for {len(graph_results)} datasets in {elapsed:.2f}s\\n\")\n\n# Print summary table\nprint(f\"{'Dataset':<28} {'Thr':<12} {'Edges':>5} {'Density':>7} {'MaxClq':>6} {'ClustC':>6}\")\nprint(\"-\" * 70)\nfor ds_name, gr in graph_results.items():\n    for thr_name, stats in gr[\"graph_stats\"].items():\n        print(f\"{ds_name:<28} {thr_name:<12} {stats['n_edges']:>5} \"\n              f\"{stats['density']:>7.4f} {stats['largest_clique_size']:>6} \"\n              f\"{stats['clustering_coefficient']:>6.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "201fb1nkos4",
   "source": "## Domain-Meaningful Interaction Checks\n\nFor datasets with known meaningful feature interactions (diabetes, breast cancer, heart), check how these domain-known pairs rank in the synergy ordering. This validates that PID synergy captures scientifically relevant interactions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "vvtpbmajrnm",
   "source": "def check_domain_pairs(\n    pid_results: list, dataset_name: str\n) -> list:\n    \"\"\"Check how known-meaningful pairs rank in synergy ordering.\"\"\"\n    if dataset_name not in DOMAIN_PAIRS:\n        return []\n\n    # Sort by synergy descending\n    sorted_results = sorted(pid_results, key=lambda r: r[\"synergy\"], reverse=True)\n    pair_to_rank = {}\n    for rank, r in enumerate(sorted_results, 1):\n        key = (r[\"feature_i\"], r[\"feature_j\"])\n        pair_to_rank[key] = rank\n        # Also store reverse\n        pair_to_rank[(r[\"feature_j\"], r[\"feature_i\"])] = rank\n\n    checks = []\n    total_pairs = len(sorted_results)\n    for fi, fj in DOMAIN_PAIRS[dataset_name]:\n        rank = pair_to_rank.get((fi, fj), None)\n        if rank is None:\n            rank = pair_to_rank.get((fj, fi), None)\n        checks.append({\n            \"feature_i\": fi,\n            \"feature_j\": fj,\n            \"synergy_rank\": rank,\n            \"total_pairs\": total_pairs,\n            \"in_top_10pct\": rank is not None and rank <= max(1, int(total_pairs * 0.1)),\n            \"in_top_25pct\": rank is not None and rank <= max(1, int(total_pairs * 0.25)),\n        })\n\n    return checks\n\n\n# Run domain checks\nfor ds_name, gr in graph_results.items():\n    domain_checks = check_domain_pairs(\n        pid_results=gr[\"pid_results\"],\n        dataset_name=ds_name,\n    )\n    if domain_checks:\n        print(f\"\\n{ds_name} — Domain-Meaningful Pair Checks:\")\n        for dc in domain_checks:\n            rank_str = f\"{dc['synergy_rank']}/{dc['total_pairs']}\" if dc['synergy_rank'] else \"not found\"\n            print(f\"  {dc['feature_i']} <-> {dc['feature_j']}: \"\n                  f\"rank {rank_str} \"\n                  f\"(top-10%: {dc['in_top_10pct']}, top-25%: {dc['in_top_25pct']})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "42frjad2dm",
   "source": "## Visualization\n\nPlot key results: (1) synergy distribution per dataset, (2) graph density across thresholds, (3) synergy vs baseline interaction correlation, and (4) stability metrics summary.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3y9dspxpq1q",
   "source": "def visualize_results(graph_results, all_datasets):\n    \"\"\"Reusable visualization function for PID synergy graph results.\"\"\"\n    ds_names = list(graph_results.keys())\n    n_datasets = len(ds_names)\n\n    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n    fig.suptitle(\"PID Synergy Graph Analysis\", fontsize=14, fontweight=\"bold\")\n\n    # ── Plot 1: Synergy distribution per dataset ────────────────────────────\n    ax = axes[0, 0]\n    synergy_data = []\n    labels = []\n    for ds_name in ds_names:\n        values = [r[\"synergy\"] for r in graph_results[ds_name][\"pid_results\"]]\n        synergy_data.append(values)\n        labels.append(ds_name.replace(\"_\", \"\\n\")[:15])\n    bp = ax.boxplot(synergy_data, labels=labels, patch_artist=True)\n    colors = plt.cm.Set3(np.linspace(0, 1, n_datasets))\n    for patch, color in zip(bp[\"boxes\"], colors):\n        patch.set_facecolor(color)\n    ax.set_title(\"Synergy Distribution per Dataset\")\n    ax.set_ylabel(\"Synergy (bits)\")\n    ax.tick_params(axis=\"x\", rotation=45, labelsize=8)\n\n    # ── Plot 2: Graph density across thresholds ─────────────────────────────\n    ax = axes[0, 1]\n    x_pos = np.arange(n_datasets)\n    width = 0.25\n    thr_names = list(THRESHOLDS.keys())\n    for i, thr_name in enumerate(thr_names):\n        densities = [\n            graph_results[ds][\"graph_stats\"][thr_name][\"density\"]\n            for ds in ds_names\n        ]\n        ax.bar(x_pos + i * width, densities, width, label=thr_name)\n    ax.set_title(\"Graph Density by Threshold\")\n    ax.set_ylabel(\"Density\")\n    ax.set_xticks(x_pos + width)\n    ax.set_xticklabels([n.replace(\"_\", \"\\n\")[:15] for n in ds_names],\n                       rotation=45, fontsize=8)\n    ax.legend(fontsize=8)\n\n    # ── Plot 3: Synergy vs baseline interaction ─────────────────────────────\n    ax = axes[1, 0]\n    for ds_name in ds_names:\n        pid_res = graph_results[ds_name][\"pid_results\"]\n        syn = [r[\"synergy\"] for r in pid_res]\n        bl = [r[\"baseline_interaction\"] for r in pid_res]\n        ax.scatter(syn, bl, alpha=0.5, s=15,\n                   label=ds_name[:12])\n    ax.set_xlabel(\"PID Synergy (bits)\")\n    ax.set_ylabel(\"Baseline Interaction (bits)\")\n    ax.set_title(\"PID Synergy vs Baseline Interaction\")\n    ax.legend(fontsize=7, loc=\"best\")\n    # Add diagonal reference\n    lims = [min(ax.get_xlim()[0], ax.get_ylim()[0]),\n            max(ax.get_xlim()[1], ax.get_ylim()[1])]\n    ax.plot(lims, lims, \"k--\", alpha=0.3, linewidth=1)\n\n    # ── Plot 4: Stability metrics ───────────────────────────────────────────\n    ax = axes[1, 1]\n    stab_names = []\n    spearman_vals = []\n    pearson_vals = []\n    for ds_name in ds_names:\n        info = all_datasets[ds_name]\n        if info.get(\"stability_spearman\") is not None:\n            stab_names.append(ds_name.replace(\"_\", \"\\n\")[:15])\n            spearman_vals.append(info[\"stability_spearman\"])\n            pearson_vals.append(info[\"stability_pearson\"])\n    if stab_names:\n        x_pos = np.arange(len(stab_names))\n        ax.bar(x_pos - 0.15, spearman_vals, 0.3, label=\"Spearman rho\")\n        ax.bar(x_pos + 0.15, pearson_vals, 0.3, label=\"Pearson r\")\n        ax.set_xticks(x_pos)\n        ax.set_xticklabels(stab_names, rotation=45, fontsize=8)\n        ax.set_ylabel(\"Correlation\")\n        ax.set_title(\"Discretization Stability (5-bin vs 10-bin)\")\n        ax.legend(fontsize=8)\n        ax.set_ylim(0, 1.1)\n    else:\n        ax.text(0.5, 0.5, \"No stability data\",\n                ha=\"center\", va=\"center\", transform=ax.transAxes)\n        ax.set_title(\"Discretization Stability\")\n\n    plt.tight_layout()\n    plt.show()\n\n    # ── Print summary table ─────────────────────────────────────────────────\n    print(f\"\\n{'Dataset':<25} {'Feat':>4} {'Pairs':>5} \"\n          f\"{'MeanSyn':>8} {'MaxSyn':>7} \"\n          f\"{'StabSp':>6} {'StabPe':>6}\")\n    print(\"-\" * 65)\n    for ds_name in ds_names:\n        info = all_datasets[ds_name]\n        pid_res = graph_results[ds_name][\"pid_results\"]\n        syn_vals = [r[\"synergy\"] for r in pid_res]\n        sp = info.get(\"stability_spearman\", None)\n        pe = info.get(\"stability_pearson\", None)\n        sp_str = f\"{sp:.4f}\" if sp is not None else \"N/A\"\n        pe_str = f\"{pe:.4f}\" if pe is not None else \"N/A\"\n        print(f\"{ds_name:<25} {info['n_features']:>4} {len(pid_res):>5} \"\n              f\"{np.mean(syn_vals):>8.4f} {np.max(syn_vals):>7.4f} \"\n              f\"{sp_str:>6} {pe_str:>6}\")\n\n\nvisualize_results(graph_results, all_datasets)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "gn1g89olxvm",
   "source": "---\n# Part 2 — Full Run (Original Parameters)\n\nLoad the complete dataset with all 12 benchmark datasets (3,597 total feature pairs) and re-run the analysis pipeline with original parameters.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "13ifrzqa2tq",
   "source": "data = load_full()\nprint(f\"Loaded {len(data['datasets'])} datasets\")\ntotal_examples = sum(len(ds[\"examples\"]) for ds in data[\"datasets\"])\nprint(f\"Total feature pairs: {total_examples}\")\nfor ds in data[\"datasets\"]:\n    print(f\"  {ds['dataset']}: {len(ds['examples'])} feature pairs\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "53m2t0racgm",
   "source": "### Parse & Build Graphs (Full Data)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "crlpl6ac466",
   "source": "t_start = time.time()\n\n# Parse all datasets\nall_datasets = parse_pid_results(data)\n\n# Build synergy graphs for all 12 datasets with original thresholds\ngraph_results = {}\nfor ds_name, ds_info in all_datasets.items():\n    pid_results = ds_info[\"pid_results\"]\n    feature_names = ds_info[\"feature_names\"]\n\n    graph_stats = {}\n    for thr_name, thr_q in THRESHOLDS.items():\n        G, thr_val = build_synergy_graph(\n            pid_results=pid_results,\n            feature_names=feature_names,\n            threshold_quantile=thr_q,\n        )\n        stats = analyze_graph(G)\n        stats[\"threshold_value\"] = round(thr_val, 6)\n        graph_stats[thr_name] = stats\n\n    graph_results[ds_name] = {\n        \"graph_stats\": graph_stats,\n        \"pid_results\": pid_results,\n        \"ds_info\": ds_info,\n    }\n\nelapsed = time.time() - t_start\nprint(f\"Processed {len(graph_results)} datasets in {elapsed:.2f}s\\n\")\n\n# Print full summary table\nprint(f\"{'Dataset':<28} {'Thr':<12} {'Edges':>5} {'Density':>7} {'MaxClq':>6} {'ClustC':>6}\")\nprint(\"-\" * 70)\nfor ds_name, gr in graph_results.items():\n    for thr_name, stats in gr[\"graph_stats\"].items():\n        print(f\"{ds_name:<28} {thr_name:<12} {stats['n_edges']:>5} \"\n              f\"{stats['density']:>7.4f} {stats['largest_clique_size']:>6} \"\n              f\"{stats['clustering_coefficient']:>6.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2y9epg17ev",
   "source": "### Domain Checks (Full Data)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "p1t2jy9xljk",
   "source": "# Run domain checks on full data\nfor ds_name, gr in graph_results.items():\n    domain_checks = check_domain_pairs(\n        pid_results=gr[\"pid_results\"],\n        dataset_name=ds_name,\n    )\n    if domain_checks:\n        print(f\"\\n{ds_name} — Domain-Meaningful Pair Checks:\")\n        for dc in domain_checks:\n            rank_str = f\"{dc['synergy_rank']}/{dc['total_pairs']}\" if dc['synergy_rank'] else \"not found\"\n            print(f\"  {dc['feature_i']} <-> {dc['feature_j']}: \"\n                  f\"rank {rank_str} \"\n                  f\"(top-10%: {dc['in_top_10pct']}, top-25%: {dc['in_top_25pct']})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9mvxlnfow0m",
   "source": "### Full Visualization",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "q21iplugctf",
   "source": "visualize_results(graph_results, all_datasets)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}