{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ky0ll6uhyzd",
   "source": "# OpenML Numeric-Only Classification Benchmarks — Demo\n\nThis notebook demonstrates the **OpenML Numeric-Only Classification Benchmarks** dataset artifact.\n\n**What it does:** Loads 8 all-numeric tabular classification datasets from OpenML, covering diverse sizes (208–2310 samples), feature counts (4–60), and class counts (2–7). All features are z-score standardized with 5-fold stratified CV fold assignments.\n\n**Datasets:** diabetes, heart-statlog, ionosphere, sonar, vehicle, segment, glass, banknote-authentication.\n\n**Domains:** medical, physics, signal processing, computer vision, forensics, image processing.\n\n- **Part 1 — Quick Demo** uses a small curated subset (~16 examples) for fast exploration.\n- **Part 2 — Full Run** loads the complete dataset (6,339 examples) with original parameters.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "rhta9y5jy2e",
   "source": "import json\nimport os\nimport time\nfrom collections import Counter\n\nimport numpy as np\nimport matplotlib.pyplot as plt",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "uvisaop8k3f",
   "source": "GITHUB_FULL_DATA_URL = \"https://raw.githubusercontent.com/AMGrobelnik/ai-invention-ac2586-synergy-guided-oblique-splits-using-part/main/openml_classif/demo/full_demo_data.json\"\nGITHUB_MINI_DATA_URL = \"https://raw.githubusercontent.com/AMGrobelnik/ai-invention-ac2586-synergy-guided-oblique-splits-using-part/main/openml_classif/demo/mini_demo_data.json\"\n\ndef _load_json(url, local_path):\n    try:\n        import urllib.request\n        with urllib.request.urlopen(url) as response:\n            return json.loads(response.read().decode())\n    except Exception: pass\n    if os.path.exists(local_path):\n        with open(local_path) as f: return json.load(f)\n    raise FileNotFoundError(f\"Could not load {local_path}\")\n\ndef load_mini():\n    return _load_json(GITHUB_MINI_DATA_URL, \"mini_demo_data.json\")\n\ndef load_full():\n    return _load_json(GITHUB_FULL_DATA_URL, \"full_demo_data.json\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "qlivlterolb",
   "source": "## Part 1 — Quick Demo (Mini Data)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0ukn5sg6zeq",
   "source": "data = load_mini()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "g43b213xt9",
   "source": "### Dataset Configuration\n\nThe 8 selected OpenML datasets span diverse domains and complexity levels. This mirrors the original script's `DATASETS` configuration dict.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "jo1cqgj4soc",
   "source": "# Final 8 selected datasets (all-numeric, no missing, 2-7 classes, 200-2500 samples)\nDATASETS = {\n    \"diabetes\": {\"data_id\": 37, \"domain\": \"medical\"},\n    \"heart-statlog\": {\"data_id\": 53, \"domain\": \"medical\"},\n    \"ionosphere\": {\"data_id\": 59, \"domain\": \"physics\"},\n    \"sonar\": {\"data_id\": 40, \"domain\": \"signal_processing\"},\n    \"vehicle\": {\"data_id\": 54, \"domain\": \"computer_vision\"},\n    \"segment\": {\"data_id\": 36, \"domain\": \"computer_vision\"},\n    \"glass\": {\"data_id\": 41, \"domain\": \"forensics\"},\n    \"banknote-authentication\": {\"data_id\": 1462, \"domain\": \"image_processing\"},\n}\n\nN_FOLDS = 5\nRANDOM_STATE = 42",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "xd0f2t3tsj",
   "source": "### Explore Data Structure\n\nPrint a summary table of all datasets: name, number of examples, features, classes, domain, and OpenML ID.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "cqnourv2m1",
   "source": "all_datasets = data[\"datasets\"]\n\nprint(f\"{'Dataset':<25s} | {'#Ex':>4s} | {'#Feat':>5s} | {'#Cls':>4s} | {'Domain':<18s} | {'OpenML ID':>9s}\")\nprint(\"-\" * 80)\nfor ds in all_datasets:\n    name = ds[\"dataset\"]\n    examples = ds[\"examples\"]\n    n_examples = len(examples)\n    ex0 = examples[0]\n    n_features = len(ex0[\"metadata_feature_names\"])\n    n_classes = ex0[\"metadata_n_classes\"]\n    domain = ex0[\"metadata_domain\"]\n    openml_id = ex0[\"metadata_openml_id\"]\n    print(f\"{name:<25s} | {n_examples:>4d} | {n_features:>5d} | {n_classes:>4d} | {domain:<18s} | {openml_id:>9d}\")\n\ntotal_examples = sum(len(d[\"examples\"]) for d in all_datasets)\nprint(f\"\\nTotal: {len(all_datasets)} datasets, {total_examples} examples\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "v6jud5ie0jc",
   "source": "### Inspect Individual Examples\n\nEach example has JSON-serialized feature values as `input`, the class label as `output`, plus metadata (fold index, feature names, task type, domain, OpenML ID).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "hwyq3fkqft",
   "source": "# Show first example from each dataset\nfor ds in all_datasets:\n    ex = ds[\"examples\"][0]\n    features = json.loads(ex[\"input\"])\n    print(f\"--- {ds['dataset']} ---\")\n    print(f\"  Label: {ex['output']}\")\n    print(f\"  Fold:  {ex['metadata_fold']}\")\n    print(f\"  Features ({len(features)}): {dict(list(features.items())[:4])}...\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9h5dmlcwm4n",
   "source": "### Analyze Class Distribution and Feature Statistics\n\nParse feature values from JSON strings and compute per-dataset statistics, matching the original script's standardization output.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "hpnp527uv3k",
   "source": "for ds in all_datasets:\n    name = ds[\"dataset\"]\n    examples = ds[\"examples\"]\n\n    # Class distribution\n    labels = [ex[\"output\"] for ex in examples]\n    class_counts = Counter(labels)\n\n    # Parse all features into a matrix\n    all_features = []\n    for ex in examples:\n        feat_vals = json.loads(ex[\"input\"])\n        all_features.append(list(feat_vals.values()))\n    feat_matrix = np.array(all_features)\n\n    # Fold distribution\n    folds = [ex[\"metadata_fold\"] for ex in examples]\n    fold_counts = Counter(folds)\n\n    print(f\"--- {name} ---\")\n    print(f\"  Classes: {dict(class_counts)}\")\n    print(f\"  Folds:   {dict(sorted(fold_counts.items()))}\")\n    if feat_matrix.size > 0:\n        print(f\"  Feature stats (z-scored): mean={feat_matrix.mean():.4f}, std={feat_matrix.std():.4f}\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "he82d1qk60o",
   "source": "### Visualization\n\nReusable visualization function: dataset overview bar chart (samples, features, classes) and per-dataset feature value distributions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "1ogvcdlpmc8",
   "source": "def visualize_datasets(datasets_list, title_prefix=\"\"):\n    \"\"\"Reusable visualization for the benchmark dataset collection.\"\"\"\n    names = []\n    n_examples_list = []\n    n_features_list = []\n    n_classes_list = []\n    domains = []\n    feat_matrices = []\n\n    for ds in datasets_list:\n        ex0 = ds[\"examples\"][0]\n        names.append(ds[\"dataset\"])\n        n_examples_list.append(len(ds[\"examples\"]))\n        n_features_list.append(len(ex0[\"metadata_feature_names\"]))\n        n_classes_list.append(ex0[\"metadata_n_classes\"])\n        domains.append(ex0[\"metadata_domain\"])\n\n        # Parse features\n        all_feats = []\n        for ex in ds[\"examples\"]:\n            vals = json.loads(ex[\"input\"])\n            all_feats.append(list(vals.values()))\n        feat_matrices.append(np.array(all_feats))\n\n    # --- Figure 1: Dataset overview ---\n    fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n    fig.suptitle(f\"{title_prefix}Dataset Overview\", fontsize=13, fontweight=\"bold\")\n\n    x = np.arange(len(names))\n    short_names = [n[:12] for n in names]\n\n    axes[0].barh(x, n_examples_list, color=\"steelblue\")\n    axes[0].set_yticks(x)\n    axes[0].set_yticklabels(short_names, fontsize=8)\n    axes[0].set_xlabel(\"# Examples\")\n    axes[0].set_title(\"Sample Count\")\n    axes[0].invert_yaxis()\n\n    axes[1].barh(x, n_features_list, color=\"coral\")\n    axes[1].set_yticks(x)\n    axes[1].set_yticklabels(short_names, fontsize=8)\n    axes[1].set_xlabel(\"# Features\")\n    axes[1].set_title(\"Feature Count\")\n    axes[1].invert_yaxis()\n\n    axes[2].barh(x, n_classes_list, color=\"mediumseagreen\")\n    axes[2].set_yticks(x)\n    axes[2].set_yticklabels(short_names, fontsize=8)\n    axes[2].set_xlabel(\"# Classes\")\n    axes[2].set_title(\"Class Count\")\n    axes[2].invert_yaxis()\n\n    plt.tight_layout()\n    plt.show()\n\n    # --- Figure 2: Feature value distributions (box plots) ---\n    fig, axes = plt.subplots(2, 4, figsize=(14, 6))\n    fig.suptitle(f\"{title_prefix}Feature Value Distributions (z-scored)\", fontsize=13, fontweight=\"bold\")\n    axes = axes.flatten()\n\n    for i, (name, feat_mat) in enumerate(zip(names, feat_matrices)):\n        ax = axes[i]\n        if feat_mat.shape[0] > 0:\n            # Show up to 10 features for readability\n            n_show = min(feat_mat.shape[1], 10)\n            ax.boxplot(feat_mat[:, :n_show], vert=True, widths=0.6,\n                       patch_artist=True,\n                       boxprops=dict(facecolor=\"lightblue\", alpha=0.7))\n        ax.set_title(name[:15], fontsize=9)\n        ax.set_xlabel(\"Feature idx\", fontsize=7)\n        ax.set_ylabel(\"Value\", fontsize=7)\n        ax.tick_params(labelsize=6)\n\n    plt.tight_layout()\n    plt.show()\n\n    # --- Summary table ---\n    print(f\"\\n{title_prefix}Summary:\")\n    print(f\"{'Dataset':<25s} | {'#Ex':>5s} | {'#Feat':>5s} | {'#Cls':>4s} | {'Domain':<18s}\")\n    print(\"-\" * 70)\n    for i in range(len(names)):\n        print(f\"{names[i]:<25s} | {n_examples_list[i]:>5d} | {n_features_list[i]:>5d} | {n_classes_list[i]:>4d} | {domains[i]:<18s}\")\n    total = sum(n_examples_list)\n    print(f\"\\nTotal: {len(names)} datasets, {total} examples\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ir2jb85vnrj",
   "source": "visualize_datasets(all_datasets, title_prefix=\"[Mini] \")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ah2no8sxe7i",
   "source": "## Part 2 — Full Run (Original Parameters)\n\nLoad the complete dataset with all 6,339 examples across 8 datasets and run the same analysis with original parameters.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "9wrvkpz0i2",
   "source": "data = load_full()\nall_datasets = data[\"datasets\"]\n\nprint(f\"Loaded {len(all_datasets)} datasets\")\ntotal_examples = sum(len(d[\"examples\"]) for d in all_datasets)\nprint(f\"Total examples: {total_examples}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "vnim2nxy5j9",
   "source": "### Full Dataset Exploration\n\nRun the same analysis on the complete dataset with all examples and original parameters.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6hxczfkluxh",
   "source": "# Full dataset summary table\nprint(f\"{'Dataset':<25s} | {'#Ex':>5s} | {'#Feat':>5s} | {'#Cls':>4s} | {'Domain':<18s} | {'OpenML ID':>9s}\")\nprint(\"-\" * 80)\nfor ds in all_datasets:\n    name = ds[\"dataset\"]\n    examples = ds[\"examples\"]\n    n_examples = len(examples)\n    ex0 = examples[0]\n    n_features = len(ex0[\"metadata_feature_names\"])\n    n_classes = ex0[\"metadata_n_classes\"]\n    domain = ex0[\"metadata_domain\"]\n    openml_id = ex0[\"metadata_openml_id\"]\n    print(f\"{name:<25s} | {n_examples:>5d} | {n_features:>5d} | {n_classes:>4d} | {domain:<18s} | {openml_id:>9d}\")\n\ntotal_examples = sum(len(d[\"examples\"]) for d in all_datasets)\nprint(f\"\\nTotal: {len(all_datasets)} datasets, {total_examples} examples\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "r4hqah1w1dd",
   "source": "# Full class distribution and feature stats\nfor ds in all_datasets:\n    name = ds[\"dataset\"]\n    examples = ds[\"examples\"]\n\n    # Class distribution\n    labels = [ex[\"output\"] for ex in examples]\n    class_counts = Counter(labels)\n\n    # Parse all features into a matrix\n    all_features = []\n    for ex in examples:\n        feat_vals = json.loads(ex[\"input\"])\n        all_features.append(list(feat_vals.values()))\n    feat_matrix = np.array(all_features)\n\n    # Fold distribution\n    folds = [ex[\"metadata_fold\"] for ex in examples]\n    fold_counts = Counter(folds)\n\n    print(f\"--- {name} ---\")\n    print(f\"  Classes: {dict(class_counts)}\")\n    print(f\"  Folds:   {dict(sorted(fold_counts.items()))}\")\n    if feat_matrix.size > 0:\n        print(f\"  Feature stats (z-scored): mean={feat_matrix.mean():.4f}, std={feat_matrix.std():.4f}\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "akttegg05t",
   "source": "visualize_datasets(all_datasets, title_prefix=\"[Full] \")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}