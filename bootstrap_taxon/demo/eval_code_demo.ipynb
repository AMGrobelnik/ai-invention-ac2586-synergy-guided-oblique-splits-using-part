{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "k50ymcrvwxf",
   "source": "# Bootstrap Effect Sizes with Failure Taxonomy — Evaluation Demo\n\nThis notebook demonstrates the evaluation pipeline for analyzing **Synergy-Guided Oblique Splits (SG-FIGS)** across 12 benchmark datasets. It implements 6 evaluation modules:\n\n| Module | Description |\n|--------|-------------|\n| **A** | Bootstrap 95% CIs on pairwise accuracy diffs |\n| **B** | Failure taxonomy (5 failure modes) |\n| **C** | Split catalog with domain annotations |\n| **D** | Synergy alignment (Spearman ρ) |\n| **E** | Success criteria verdicts |\n| **F** | Paper narrative synthesis |\n\n**Part 1** runs a quick demo on a 4-dataset subset with reduced bootstrap resamples.\n**Part 2** runs the full evaluation on all 12 datasets with original parameters.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3z5ahvjd1vn",
   "source": "import json\nimport math\nfrom itertools import combinations\n\nimport numpy as np\nfrom scipy import stats as scipy_stats\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dcrmulj0rb",
   "source": "GITHUB_FULL_DATA_URL = \"https://raw.githubusercontent.com/AMGrobelnik/ai-invention-ac2586-synergy-guided-oblique-splits-using-part/main/bootstrap_taxon/demo/full_demo_data.json\"\nGITHUB_MINI_DATA_URL = \"https://raw.githubusercontent.com/AMGrobelnik/ai-invention-ac2586-synergy-guided-oblique-splits-using-part/main/bootstrap_taxon/demo/mini_demo_data.json\"\nimport json, os\n\ndef _load_json(url, local_path):\n    try:\n        import urllib.request\n        with urllib.request.urlopen(url) as response:\n            return json.loads(response.read().decode())\n    except Exception: pass\n    if os.path.exists(local_path):\n        with open(local_path) as f: return json.load(f)\n    raise FileNotFoundError(f\"Could not load {local_path}\")\n\ndef load_mini():\n    return _load_json(GITHUB_MINI_DATA_URL, \"mini_demo_data.json\")\n\ndef load_full():\n    return _load_json(GITHUB_FULL_DATA_URL, \"full_demo_data.json\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3cz2ny4jeq8",
   "source": "## Constants and Configuration\n\nMethods compared, pairwise comparisons, and domain annotations for oblique split interpretation.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "tp0zclucrxt",
   "source": "# ── Constants ────────────────────────────────────────────────────────────────\nMETHODS = [\"FIGS\", \"RO-FIGS\", \"SG-FIGS-10\", \"SG-FIGS-25\", \"SG-FIGS-50\", \"GradientBoosting\"]\nTARGET_MAX_RULES = 10\nRNG_SEED = 42\n\n# The 6 key pairwise comparisons from the artifact proposal\nPAIRWISE_COMPARISONS = [\n    (\"FIGS\", \"RO-FIGS\"),\n    (\"FIGS\", \"SG-FIGS-25\"),\n    (\"RO-FIGS\", \"SG-FIGS-25\"),\n    (\"FIGS\", \"SG-FIGS-10\"),\n    (\"FIGS\", \"SG-FIGS-50\"),\n    (\"GradientBoosting\", \"FIGS\"),\n]\n\n# Domain annotation map for oblique splits\nDOMAIN_ANNOTATIONS = {\n    \"diabetes\": {\n        \"features_annotation\": \"glucose-BMI-age metabolic risk triad\",\n        \"domain\": \"clinical diabetes prediction\",\n        \"interpretation\": (\n            \"plas (plasma glucose), mass (BMI), and age form a clinically \"\n            \"known metabolic syndrome triad for diabetes risk assessment\"\n        ),\n    },\n    \"heart_statlog\": {\n        \"features_annotation\": \"cardiovascular anatomy indicators\",\n        \"domain\": \"cardiac disease diagnosis\",\n        \"interpretation\": (\n            \"number_of_major_vessels and thal (thalassemia type) are key \"\n            \"cardiovascular anatomy indicators used in clinical cardiology\"\n        ),\n    },\n    \"breast_cancer\": {\n        \"features_annotation\": \"tumor morphology measures\",\n        \"domain\": \"breast cancer malignancy classification\",\n        \"interpretation\": (\n            \"worst_radius, worst_smoothness, and worst_concave_points capture \"\n            \"tumor morphology — larger, rougher tumors with more concavities \"\n            \"are hallmarks of malignancy\"\n        ),\n    },\n}",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "97m4oe3t2a9",
   "source": "## Evaluation Module Functions\n\nSix modules copied from `eval.py` with minimal changes (removed file I/O, replaced logging with print).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "reyfo46znc9",
   "source": "# ═══════════════════════════════════════════════════════════════════════════\n# Module A: Bootstrap Effect Sizes\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef module_a_bootstrap(\n    results: dict[str, dict[str, list[float]]],\n    n_bootstrap: int = 10_000,\n) -> list[dict]:\n    \"\"\"Compute bootstrap 95% CIs on pairwise method accuracy differences.\"\"\"\n    print(f\"Module A: Computing bootstrap effect sizes (n_bootstrap={n_bootstrap})\")\n    rng = np.random.default_rng(RNG_SEED)\n    all_datasets = sorted(results.keys())\n    comparisons_out = []\n\n    for method_a, method_b in PAIRWISE_COMPARISONS:\n        # Compute per-dataset mean accuracy differences\n        diffs = []\n        for ds in all_datasets:\n            accs_a = results[ds].get(method_a, [])\n            accs_b = results[ds].get(method_b, [])\n            if not accs_a or not accs_b:\n                continue\n            mean_a = float(np.mean(accs_a))\n            mean_b = float(np.mean(accs_b))\n            diffs.append(mean_a - mean_b)\n\n        if len(diffs) < 2:\n            print(\n                f\"  Skipping {method_a} vs {method_b}: only {len(diffs)} datasets\"\n            )\n            continue\n\n        diffs_arr = np.array(diffs)\n        point_estimate = float(np.mean(diffs_arr))\n\n        # Bootstrap resampling\n        boot_means = np.empty(n_bootstrap)\n        n = len(diffs_arr)\n        for i in range(n_bootstrap):\n            sample = rng.choice(diffs_arr, size=n, replace=True)\n            boot_means[i] = np.mean(sample)\n\n        ci_lower = float(np.percentile(boot_means, 2.5))\n        ci_upper = float(np.percentile(boot_means, 97.5))\n        includes_zero = bool(ci_lower <= 0 <= ci_upper)\n\n        comp = {\n            \"comparison\": f\"{method_a} - {method_b}\",\n            \"method_a\": method_a,\n            \"method_b\": method_b,\n            \"n_datasets\": len(diffs),\n            \"point_estimate\": round(point_estimate, 6),\n            \"ci_lower_95\": round(ci_lower, 6),\n            \"ci_upper_95\": round(ci_upper, 6),\n            \"ci_includes_zero\": includes_zero,\n            \"per_dataset_diffs\": {\n                ds: round(d, 6) for ds, d in zip(all_datasets, diffs)\n            },\n            \"boot_mean\": round(float(np.mean(boot_means)), 6),\n            \"boot_std\": round(float(np.std(boot_means)), 6),\n        }\n        comparisons_out.append(comp)\n        print(\n            f\"  {method_a} - {method_b}: \"\n            f\"Δ={point_estimate:.4f}, CI=[{ci_lower:.4f}, {ci_upper:.4f}], \"\n            f\"includes_zero={includes_zero}\"\n        )\n\n    return comparisons_out",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "qo0vjonhx3m",
   "source": "# ═══════════════════════════════════════════════════════════════════════════\n# Module B: Failure Taxonomy\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef module_b_failure_taxonomy(\n    results: dict[str, dict[str, list[float]]],\n    oblique_info: dict[str, dict[str, list[dict]]],\n    metadata: dict,\n) -> list[dict]:\n    \"\"\"Classify each dataset into failure modes using sequential decision rules.\"\"\"\n    print(\"Module B: Computing failure taxonomy\")\n    all_datasets = sorted(results.keys())\n    synergy_stability = metadata.get(\"synergy_graph_stability\", {})\n    taxonomy = []\n\n    for ds in all_datasets:\n        figs_accs = results[ds].get(\"FIGS\", [])\n        ro_accs = results[ds].get(\"RO-FIGS\", [])\n        sg25_accs = results[ds].get(\"SG-FIGS-25\", [])\n\n        figs_mean = float(np.mean(figs_accs)) if figs_accs else 0.0\n        ro_mean = float(np.mean(ro_accs)) if ro_accs else 0.0\n        sg25_mean = float(np.mean(sg25_accs)) if sg25_accs else 0.0\n\n        # Check oblique_fraction for SG-FIGS-25 across all folds\n        sg25_oblique = oblique_info[ds].get(\"SG-FIGS-25\", [])\n        all_oblique_zero = all(\n            e.get(\"oblique_fraction\", 0.0) == 0.0 for e in sg25_oblique\n        ) if sg25_oblique else True\n\n        # Get synergy stability\n        stab = synergy_stability.get(ds, {})\n        jaccard = stab.get(\"mean_jaccard\", 0.0)\n\n        # Get n_synergy_edges at 25% threshold (from any fold)\n        n_synergy_edges = 0\n        for entry in sg25_oblique:\n            if entry.get(\"n_synergy_edges\", 0) > 0:\n                n_synergy_edges = entry[\"n_synergy_edges\"]\n                break\n\n        # Sequential decision rules\n        diff_figs_ro = (figs_mean - ro_mean) * 100  # in percentage points\n        diff_sg25_ro = (sg25_mean - ro_mean) * 100\n\n        if all_oblique_zero:\n            failure_mode = \"graph_too_sparse\"\n        elif diff_figs_ro > 5:\n            failure_mode = \"oblique_incompatible\"\n        elif diff_sg25_ro < -3:\n            failure_mode = \"synergy_harmful\"\n        elif abs(diff_sg25_ro) <= 3:\n            failure_mode = \"synergy_neutral\"\n        else:\n            failure_mode = \"synergy_beneficial\"\n\n        row = {\n            \"dataset\": ds,\n            \"failure_mode\": failure_mode,\n            \"figs_mean_acc\": round(figs_mean, 4),\n            \"ro_figs_mean_acc\": round(ro_mean, 4),\n            \"sg25_mean_acc\": round(sg25_mean, 4),\n            \"figs_minus_ro_pp\": round(diff_figs_ro, 2),\n            \"sg25_minus_ro_pp\": round(diff_sg25_ro, 2),\n            \"oblique_fraction_all_zero\": all_oblique_zero,\n            \"synergy_stability_jaccard\": round(jaccard, 4),\n            \"n_synergy_edges_25pct\": n_synergy_edges,\n        }\n        taxonomy.append(row)\n        print(f\"  {ds}: {failure_mode} (FIGS-RO={diff_figs_ro:+.1f}pp, SG25-RO={diff_sg25_ro:+.1f}pp)\")\n\n    return taxonomy",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c1oj82z18e",
   "source": "# ═══════════════════════════════════════════════════════════════════════════\n# Module C: Split Catalog\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef module_c_split_catalog(metadata: dict) -> dict:\n    \"\"\"Parse qualitative_split_inspection entries and annotate with domain info.\"\"\"\n    print(\"Module C: Building split catalog\")\n    inspections = metadata.get(\"qualitative_split_inspection\", {})\n\n    catalog = []\n    total_oblique = 0\n    total_axis_aligned = 0\n\n    for combo_key, splits in inspections.items():\n        # Parse dataset name from key like \"diabetes_SG-FIGS-10\"\n        parts = combo_key.rsplit(\"_SG-FIGS-\", 1)\n        if len(parts) == 2:\n            ds_name = parts[0]\n            method_name = f\"SG-FIGS-{parts[1]}\"\n        else:\n            ds_name = combo_key\n            method_name = \"unknown\"\n\n        oblique_splits_in_combo = []\n        axis_aligned_in_combo = 0\n\n        for split in splits:\n            if split.get(\"is_oblique\", False) or split.get(\"type\") == \"oblique\":\n                total_oblique += 1\n                features = split.get(\"features\", [])\n                weights = split.get(\"weights\", [])\n                abs_weights = [abs(w) for w in weights]\n                pairwise_synergies = split.get(\"pairwise_synergies\", [])\n                impurity_reduction = split.get(\"impurity_reduction\", 0.0)\n\n                # Domain annotation\n                annotation = DOMAIN_ANNOTATIONS.get(ds_name, {})\n\n                oblique_entry = {\n                    \"combo_key\": combo_key,\n                    \"dataset\": ds_name,\n                    \"method\": method_name,\n                    \"tree\": split.get(\"tree\", -1),\n                    \"split_index\": split.get(\"split_index\", -1),\n                    \"depth\": split.get(\"depth\", -1),\n                    \"features\": features,\n                    \"weights\": [round(w, 6) for w in weights],\n                    \"abs_weights\": [round(w, 6) for w in abs_weights],\n                    \"bias\": round(split.get(\"bias\", 0.0), 6),\n                    \"threshold\": round(split.get(\"threshold\", 0.0), 6),\n                    \"impurity_reduction\": round(impurity_reduction, 4),\n                    \"pairwise_synergies\": pairwise_synergies,\n                    \"rule_str\": split.get(\"rule_str\", \"\"),\n                    \"n_features\": len(features),\n                    \"domain_annotation\": annotation.get(\"features_annotation\", \"\"),\n                    \"domain\": annotation.get(\"domain\", \"\"),\n                    \"domain_interpretation\": annotation.get(\"interpretation\", \"\"),\n                }\n                oblique_splits_in_combo.append(oblique_entry)\n            else:\n                total_axis_aligned += 1\n                axis_aligned_in_combo += 1\n\n        catalog.append({\n            \"combo_key\": combo_key,\n            \"dataset\": ds_name,\n            \"method\": method_name,\n            \"n_oblique_splits\": len(oblique_splits_in_combo),\n            \"n_axis_aligned_splits\": axis_aligned_in_combo,\n            \"oblique_splits\": oblique_splits_in_combo,\n        })\n\n    total_splits = total_oblique + total_axis_aligned\n    oblique_activation_rate = (\n        total_oblique / total_splits if total_splits > 0 else 0.0\n    )\n\n    summary = {\n        \"n_inspection_combos\": len(inspections),\n        \"total_oblique_splits\": total_oblique,\n        \"total_axis_aligned_splits\": total_axis_aligned,\n        \"total_splits\": total_splits,\n        \"oblique_activation_rate\": round(oblique_activation_rate, 4),\n        \"catalog\": catalog,\n    }\n\n    print(\n        f\"  {total_oblique} oblique + {total_axis_aligned} axis-aligned = \"\n        f\"{total_splits} total splits, activation rate = \"\n        f\"{oblique_activation_rate:.1%}\"\n    )\n    return summary",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dgrzuj4duf",
   "source": "# ═══════════════════════════════════════════════════════════════════════════\n# Module D: Synergy Alignment Score\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef _mean_pairwise_synergy_for_feature(\n    feature: str,\n    all_features: list[str],\n    synergy_map: dict[tuple[str, str], float],\n) -> float:\n    \"\"\"Compute mean pairwise synergy of a feature with other features in the split.\"\"\"\n    other_features = [f for f in all_features if f != feature]\n    if not other_features:\n        return 0.0\n    total = 0.0\n    count = 0\n    for other in other_features:\n        key = tuple(sorted([feature, other]))\n        if key in synergy_map:\n            total += synergy_map[key]\n            count += 1\n    return total / count if count > 0 else 0.0\n\n\ndef module_d_synergy_alignment(split_catalog: dict) -> dict:\n    \"\"\"Compute Spearman rank correlation between |weight| and mean pairwise synergy.\"\"\"\n    print(\"Module D: Computing synergy alignment scores\")\n    alignment_results = []\n\n    for combo_entry in split_catalog[\"catalog\"]:\n        for oblique_split in combo_entry[\"oblique_splits\"]:\n            features = oblique_split[\"features\"]\n            abs_weights = oblique_split[\"abs_weights\"]\n            pairwise_synergies = oblique_split[\"pairwise_synergies\"]\n            n_features = len(features)\n\n            # Build synergy map\n            synergy_map: dict[tuple[str, str], float] = {}\n            for ps in pairwise_synergies:\n                pair = ps[\"pair\"]\n                key = tuple(sorted(pair))\n                synergy_map[key] = ps[\"synergy\"]\n\n            # Compute mean pairwise synergy for each feature\n            mean_synergies = []\n            for feat in features:\n                ms = _mean_pairwise_synergy_for_feature(feat, features, synergy_map)\n                mean_synergies.append(ms)\n\n            # Check if top-2 highest-|weight| features correspond to highest-synergy pair\n            if len(features) >= 2:\n                weight_ranked = sorted(\n                    range(len(features)), key=lambda i: abs_weights[i], reverse=True\n                )\n                top2_features = {features[weight_ranked[0]], features[weight_ranked[1]]}\n                # Find highest-synergy pair\n                if pairwise_synergies:\n                    best_pair_entry = max(pairwise_synergies, key=lambda x: x[\"synergy\"])\n                    best_pair = set(best_pair_entry[\"pair\"])\n                    top2_matches_highest_synergy = top2_features == best_pair\n                else:\n                    top2_matches_highest_synergy = False\n            else:\n                top2_matches_highest_synergy = False\n\n            # Compute Spearman correlation\n            if n_features >= 3:\n                rho, p_value = scipy_stats.spearmanr(abs_weights, mean_synergies)\n                if math.isnan(rho):\n                    rho = 0.0\n                    p_value = 1.0\n                alignment_entry = {\n                    \"combo_key\": oblique_split[\"combo_key\"],\n                    \"dataset\": oblique_split[\"dataset\"],\n                    \"method\": oblique_split[\"method\"],\n                    \"n_features\": n_features,\n                    \"features\": features,\n                    \"abs_weights\": abs_weights,\n                    \"mean_pairwise_synergies\": [round(s, 6) for s in mean_synergies],\n                    \"spearman_rho\": round(float(rho), 4),\n                    \"spearman_p_value\": round(float(p_value), 4),\n                    \"computable\": True,\n                    \"top2_matches_highest_synergy\": top2_matches_highest_synergy,\n                }\n            else:\n                # Only 2 features — report raw alignment\n                alignment_entry = {\n                    \"combo_key\": oblique_split[\"combo_key\"],\n                    \"dataset\": oblique_split[\"dataset\"],\n                    \"method\": oblique_split[\"method\"],\n                    \"n_features\": n_features,\n                    \"features\": features,\n                    \"abs_weights\": abs_weights,\n                    \"mean_pairwise_synergies\": [round(s, 6) for s in mean_synergies],\n                    \"spearman_rho\": None,\n                    \"spearman_p_value\": None,\n                    \"computable\": False,\n                    \"raw_weight_synergy_pairs\": list(zip(abs_weights, mean_synergies)),\n                    \"top2_matches_highest_synergy\": top2_matches_highest_synergy,\n                }\n\n            alignment_results.append(alignment_entry)\n            rho_str = f\"ρ={alignment_entry['spearman_rho']}\" if alignment_entry[\"computable\"] else \"N/A (2 features)\"\n            print(\n                f\"  {oblique_split['combo_key']}: {rho_str}, \"\n                f\"top2_match={top2_matches_highest_synergy}\"\n            )\n\n    # Aggregate\n    computable = [r for r in alignment_results if r[\"computable\"]]\n    mean_rho = float(np.mean([r[\"spearman_rho\"] for r in computable])) if computable else 0.0\n\n    return {\n        \"alignments\": alignment_results,\n        \"n_total\": len(alignment_results),\n        \"n_computable\": len(computable),\n        \"mean_spearman_rho\": round(mean_rho, 4),\n        \"individual_rhos\": [\n            {\"combo_key\": r[\"combo_key\"], \"rho\": r[\"spearman_rho\"]}\n            for r in computable\n        ],\n    }",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "lqp6akps1n",
   "source": "# ═══════════════════════════════════════════════════════════════════════════\n# Module E: Success Criteria Verdicts\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef module_e_success_verdicts(\n    bootstrap_results: list[dict],\n    split_catalog: dict,\n    alignment_results: dict,\n    taxonomy: list[dict],\n    oblique_info: dict,\n) -> list[dict]:\n    \"\"\"Evaluate 3 hypothesis success criteria.\"\"\"\n    print(\"Module E: Computing success criteria verdicts\")\n    verdicts = []\n\n    # --- Criterion 1: Accuracy parity with fewer splits ---\n    figs_sg25_ci = None\n    ro_sg25_ci = None\n    for comp in bootstrap_results:\n        if comp[\"method_a\"] == \"FIGS\" and comp[\"method_b\"] == \"SG-FIGS-25\":\n            figs_sg25_ci = comp\n        if comp[\"method_a\"] == \"RO-FIGS\" and comp[\"method_b\"] == \"SG-FIGS-25\":\n            ro_sg25_ci = comp\n\n    sg_loses_to_figs = (\n        figs_sg25_ci is not None\n        and figs_sg25_ci[\"point_estimate\"] > 0\n        and not figs_sg25_ci[\"ci_includes_zero\"]\n    )\n\n    # Compute mean oblique fraction for SG-FIGS-25\n    sg25_oblique_fracs = []\n    for ds, methods in oblique_info.items():\n        for entry in methods.get(\"SG-FIGS-25\", []):\n            sg25_oblique_fracs.append(entry.get(\"oblique_fraction\", 0.0))\n    mean_oblique_frac = float(np.mean(sg25_oblique_fracs)) if sg25_oblique_fracs else 0.0\n\n    if sg_loses_to_figs:\n        verdict_1 = \"DISCONFIRMED\"\n        evidence_1 = (\n            f\"SG-FIGS-25 loses {figs_sg25_ci['point_estimate']*100:.1f}pp to FIGS on average \"\n            f\"(CI=[{figs_sg25_ci['ci_lower_95']*100:.1f}, {figs_sg25_ci['ci_upper_95']*100:.1f}]pp). \"\n            f\"Mean oblique fraction for SG-FIGS-25: {mean_oblique_frac:.1%}.\"\n        )\n    elif figs_sg25_ci and figs_sg25_ci[\"ci_includes_zero\"]:\n        verdict_1 = \"PARTIALLY_CONFIRMED\"\n        evidence_1 = (\n            f\"FIGS vs SG-FIGS-25 difference CI includes zero \"\n            f\"([{figs_sg25_ci['ci_lower_95']*100:.1f}, {figs_sg25_ci['ci_upper_95']*100:.1f}]pp), \"\n            f\"suggesting parity is possible but not conclusively demonstrated.\"\n        )\n    else:\n        verdict_1 = \"CONFIRMED\"\n        evidence_1 = \"SG-FIGS-25 achieves accuracy parity with standard FIGS.\"\n\n    verdicts.append({\n        \"criterion\": \"Accuracy parity with fewer splits\",\n        \"verdict\": verdict_1,\n        \"evidence\": evidence_1,\n        \"key_metrics\": {\n            \"figs_vs_sg25_point_estimate_pp\": round(\n                figs_sg25_ci[\"point_estimate\"] * 100, 2\n            ) if figs_sg25_ci else None,\n            \"ro_vs_sg25_point_estimate_pp\": round(\n                ro_sg25_ci[\"point_estimate\"] * 100, 2\n            ) if ro_sg25_ci else None,\n            \"mean_oblique_fraction_sg25\": round(mean_oblique_frac, 4),\n        },\n    })\n\n    # --- Criterion 2: Higher interpretability score ---\n    oblique_rate = split_catalog[\"oblique_activation_rate\"]\n    mean_rho = alignment_results[\"mean_spearman_rho\"]\n\n    if oblique_rate > 0.2 and mean_rho > 0.3:\n        verdict_2 = \"CONFIRMED\"\n    elif oblique_rate > 0.05 or mean_rho > 0:\n        verdict_2 = \"PARTIALLY_CONFIRMED\"\n    else:\n        verdict_2 = \"DISCONFIRMED\"\n\n    evidence_2 = (\n        f\"Oblique activation rate: {oblique_rate:.1%} (across \"\n        f\"{split_catalog['total_splits']} total splits). \"\n        f\"Mean synergy alignment (Spearman ρ): {mean_rho:.3f}. \"\n        f\"Oblique splits combine synergistic features but low activation rate \"\n        f\"limits overall interpretability improvement.\"\n    )\n    verdicts.append({\n        \"criterion\": \"Higher interpretability score\",\n        \"verdict\": verdict_2,\n        \"evidence\": evidence_2,\n        \"key_metrics\": {\n            \"oblique_activation_rate\": oblique_rate,\n            \"mean_synergy_alignment_rho\": mean_rho,\n            \"total_oblique_splits\": split_catalog[\"total_oblique_splits\"],\n            \"total_splits\": split_catalog[\"total_splits\"],\n        },\n    })\n\n    # --- Criterion 3: Domain-meaningful splits on 3+ datasets ---\n    datasets_with_domain = set()\n    for combo in split_catalog[\"catalog\"]:\n        for osplit in combo[\"oblique_splits\"]:\n            if osplit[\"domain_annotation\"]:\n                datasets_with_domain.add(osplit[\"dataset\"])\n\n    n_domain_meaningful = len(datasets_with_domain)\n    if n_domain_meaningful >= 3:\n        verdict_3 = \"CONFIRMED\"\n    elif n_domain_meaningful >= 1:\n        verdict_3 = \"PARTIALLY_CONFIRMED\"\n    else:\n        verdict_3 = \"DISCONFIRMED\"\n\n    evidence_3 = (\n        f\"{n_domain_meaningful} datasets show domain-meaningful oblique splits: \"\n        f\"{sorted(datasets_with_domain)}. \"\n    )\n    for ds in sorted(datasets_with_domain):\n        ann = DOMAIN_ANNOTATIONS.get(ds, {})\n        if ann:\n            evidence_3 += f\"{ds}: {ann.get('interpretation', '')}. \"\n\n    verdicts.append({\n        \"criterion\": \"Domain-meaningful splits on 3+ datasets\",\n        \"verdict\": verdict_3,\n        \"evidence\": evidence_3,\n        \"key_metrics\": {\n            \"n_datasets_with_domain_meaningful_splits\": n_domain_meaningful,\n            \"datasets\": sorted(datasets_with_domain),\n        },\n    })\n\n    for v in verdicts:\n        print(f\"  {v['criterion']}: {v['verdict']}\")\n\n    return verdicts",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bdlwyxvum4l",
   "source": "# ═══════════════════════════════════════════════════════════════════════════\n# Module F: Paper Narrative Synthesis\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef module_f_narrative(\n    bootstrap_results: list[dict],\n    taxonomy: list[dict],\n    split_catalog: dict,\n    alignment_results: dict,\n    verdicts: list[dict],\n    metadata: dict,\n) -> dict:\n    \"\"\"Synthesize paper narrative: findings, contributions, lessons.\"\"\"\n    print(\"Module F: Synthesizing paper narrative\")\n\n    # Failure mode counts\n    mode_counts: dict[str, int] = {}\n    for row in taxonomy:\n        m = row[\"failure_mode\"]\n        mode_counts[m] = mode_counts.get(m, 0) + 1\n\n    # Synergy timing\n    total_time = metadata.get(\"total_runtime_seconds\", 0)\n\n    # Synergy stability range\n    stab = metadata.get(\"synergy_graph_stability\", {})\n    jaccards = [v.get(\"mean_jaccard\", 0) for v in stab.values()]\n    jaccard_min = min(jaccards) if jaccards else 0\n    jaccard_max = max(jaccards) if jaccards else 0\n\n    n_datasets = len(taxonomy)\n\n    # Key findings ranked by importance\n    key_findings = [\n        {\n            \"rank\": 1,\n            \"finding\": \"SG-FIGS does not improve accuracy over standard FIGS\",\n            \"detail\": (\n                \"Bootstrap CIs show SG-FIGS-25 loses ~5-10pp vs FIGS across \"\n                f\"{n_datasets} datasets. The accuracy parity criterion is DISCONFIRMED.\"\n            ),\n        },\n        {\n            \"rank\": 2,\n            \"finding\": \"Oblique splits produce domain-meaningful feature combinations\",\n            \"detail\": (\n                \"diabetes (plas+mass+age = metabolic triad), heart (vessels+thal = \"\n                \"cardiovascular anatomy), breast_cancer (worst_radius+smoothness+\"\n                \"concave_points = tumor morphology) — all clinically meaningful.\"\n            ),\n        },\n        {\n            \"rank\": 3,\n            \"finding\": \"Synergy graph sparsity is the primary failure mode\",\n            \"detail\": (\n                f\"{mode_counts.get('graph_too_sparse', 0)}/{n_datasets} datasets have zero \"\n                f\"oblique splits at 25% threshold due to sparse synergy graphs.\"\n            ),\n        },\n        {\n            \"rank\": 4,\n            \"finding\": \"Synergy alignment with Ridge weights is mixed\",\n            \"detail\": (\n                f\"Mean Spearman ρ = {alignment_results['mean_spearman_rho']:.3f}. \"\n                f\"Positive for breast_cancer, negative for heart/diabetes — \"\n                f\"synergy identifies related features but not optimal linear combos.\"\n            ),\n        },\n        {\n            \"rank\": 5,\n            \"finding\": \"PID computation is fast and scalable\",\n            \"detail\": (\n                f\"Total pipeline runtime: {total_time:.0f}s across {n_datasets} datasets. \"\n                f\"Even sonar (1770 pairs) completes in ~17s.\"\n            ),\n        },\n        {\n            \"rank\": 6,\n            \"finding\": \"Synergy graph stability varies widely across datasets\",\n            \"detail\": (\n                f\"Jaccard stability ranges from {jaccard_min:.2f} to {jaccard_max:.2f}. \"\n                f\"banknote (1.0) is perfectly stable, sonar (0.25) highly unstable.\"\n            ),\n        },\n        {\n            \"rank\": 7,\n            \"finding\": \"Oblique activation rate is low at ~10%\",\n            \"detail\": (\n                f\"{split_catalog['total_oblique_splits']} oblique splits out of \"\n                f\"{split_catalog['total_splits']} total = \"\n                f\"{split_catalog['oblique_activation_rate']:.1%} activation rate.\"\n            ),\n        },\n    ]\n\n    # Lessons learned\n    lessons = [\n        {\n            \"lesson\": \"Feature synergy ≠ predictive complementarity for linear projections\",\n            \"detail\": (\n                \"PID synergy captures information-theoretic interactions but Ridge \"\n                \"regression needs a different kind of feature relationship.\"\n            ),\n        },\n        {\n            \"lesson\": \"Sparse synergy graphs need adaptive thresholding\",\n            \"detail\": (\n                \"Fixed percentile thresholds (10%, 25%, 50%) fail for low-dimensional \"\n                \"datasets with few feature pairs.\"\n            ),\n        },\n        {\n            \"lesson\": \"Negative results are publishable when paired with diagnostic analysis\",\n            \"detail\": (\n                \"The failure taxonomy and domain-meaningful split discovery transform \"\n                \"a negative accuracy result into actionable insights.\"\n            ),\n        },\n    ]\n\n    return {\n        \"key_findings\": key_findings,\n        \"lessons_learned\": lessons,\n        \"failure_mode_distribution\": mode_counts,\n    }",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "kxlwi1y2rt",
   "source": "## Visualization Function\n\nReusable function that displays bootstrap CIs, failure taxonomy distribution, and success criteria verdicts.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "36jbwzrhynv",
   "source": "def visualize_results(\n    bootstrap_results: list[dict],\n    taxonomy: list[dict],\n    split_catalog: dict,\n    alignment_results: dict,\n    verdicts: list[dict],\n    narrative: dict,\n    title_prefix: str = \"\",\n):\n    \"\"\"Visualize evaluation results with tables and plots.\"\"\"\n    # ── Print summary tables ─────────────────────────────────────────────\n    print(f\"\\n{'='*60}\")\n    print(f\"{title_prefix}EVALUATION RESULTS SUMMARY\")\n    print(f\"{'='*60}\")\n\n    # Bootstrap CI table\n    print(f\"\\n--- Module A: Bootstrap Effect Sizes ---\")\n    print(f\"{'Comparison':<30} {'Δ':>8} {'CI Lower':>10} {'CI Upper':>10} {'Zero?':>6}\")\n    print(\"-\" * 66)\n    for c in bootstrap_results:\n        print(\n            f\"{c['comparison']:<30} {c['point_estimate']:>8.4f} \"\n            f\"{c['ci_lower_95']:>10.4f} {c['ci_upper_95']:>10.4f} \"\n            f\"{'YES' if c['ci_includes_zero'] else 'NO':>6}\"\n        )\n\n    # Failure taxonomy table\n    print(f\"\\n--- Module B: Failure Taxonomy ---\")\n    print(f\"{'Dataset':<18} {'Mode':<22} {'FIGS':>6} {'RO':>6} {'SG25':>6}\")\n    print(\"-\" * 62)\n    for t in taxonomy:\n        print(\n            f\"{t['dataset']:<18} {t['failure_mode']:<22} \"\n            f\"{t['figs_mean_acc']:>6.3f} {t['ro_figs_mean_acc']:>6.3f} \"\n            f\"{t['sg25_mean_acc']:>6.3f}\"\n        )\n\n    # Split catalog summary\n    print(f\"\\n--- Module C: Split Catalog ---\")\n    print(f\"  Total oblique: {split_catalog['total_oblique_splits']}\")\n    print(f\"  Total axis-aligned: {split_catalog['total_axis_aligned_splits']}\")\n    print(f\"  Activation rate: {split_catalog['oblique_activation_rate']:.1%}\")\n\n    # Synergy alignment\n    print(f\"\\n--- Module D: Synergy Alignment ---\")\n    print(f\"  Mean Spearman ρ: {alignment_results['mean_spearman_rho']:.4f}\")\n    for r in alignment_results.get(\"individual_rhos\", []):\n        print(f\"    {r['combo_key']}: ρ={r['rho']}\")\n\n    # Verdicts\n    print(f\"\\n--- Module E: Success Criteria ---\")\n    for v in verdicts:\n        symbol = {\"CONFIRMED\": \"✓\", \"PARTIALLY_CONFIRMED\": \"~\", \"DISCONFIRMED\": \"✗\"}\n        print(f\"  {symbol.get(v['verdict'], '?')} {v['criterion']}: {v['verdict']}\")\n\n    # Key findings\n    print(f\"\\n--- Module F: Key Findings ---\")\n    for f in narrative[\"key_findings\"]:\n        print(f\"  #{f['rank']}: {f['finding']}\")\n\n    # ── Matplotlib visualization ─────────────────────────────────────────\n    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n    fig.suptitle(f\"{title_prefix}Bootstrap Effect Sizes & Failure Taxonomy\", fontsize=14)\n\n    # Plot 1: Bootstrap CIs\n    ax = axes[0]\n    labels = [c[\"comparison\"] for c in bootstrap_results]\n    points = [c[\"point_estimate\"] * 100 for c in bootstrap_results]\n    lowers = [c[\"ci_lower_95\"] * 100 for c in bootstrap_results]\n    uppers = [c[\"ci_upper_95\"] * 100 for c in bootstrap_results]\n    y_pos = range(len(labels))\n\n    colors = [\"#d32f2f\" if not c[\"ci_includes_zero\"] else \"#4caf50\" for c in bootstrap_results]\n    ax.barh(y_pos, points, color=colors, alpha=0.7, height=0.6)\n    for i in y_pos:\n        ax.plot([lowers[i], uppers[i]], [i, i], color=\"black\", linewidth=2)\n        ax.plot([lowers[i], lowers[i]], [i - 0.15, i + 0.15], color=\"black\", linewidth=2)\n        ax.plot([uppers[i], uppers[i]], [i - 0.15, i + 0.15], color=\"black\", linewidth=2)\n    ax.axvline(x=0, color=\"gray\", linestyle=\"--\", linewidth=1)\n    ax.set_yticks(list(y_pos))\n    ax.set_yticklabels(labels, fontsize=8)\n    ax.set_xlabel(\"Accuracy Difference (pp)\")\n    ax.set_title(\"Bootstrap 95% CIs\")\n\n    # Plot 2: Failure mode distribution\n    ax = axes[1]\n    mode_counts = narrative[\"failure_mode_distribution\"]\n    mode_labels = list(mode_counts.keys())\n    mode_values = list(mode_counts.values())\n    mode_colors = {\n        \"graph_too_sparse\": \"#ff9800\",\n        \"oblique_incompatible\": \"#f44336\",\n        \"synergy_harmful\": \"#e91e63\",\n        \"synergy_neutral\": \"#9e9e9e\",\n        \"synergy_beneficial\": \"#4caf50\",\n    }\n    bar_colors = [mode_colors.get(m, \"#2196f3\") for m in mode_labels]\n    ax.bar(range(len(mode_labels)), mode_values, color=bar_colors, alpha=0.8)\n    ax.set_xticks(range(len(mode_labels)))\n    ax.set_xticklabels([m.replace(\"_\", \"\\n\") for m in mode_labels], fontsize=7)\n    ax.set_ylabel(\"Number of Datasets\")\n    ax.set_title(\"Failure Mode Distribution\")\n    for i, v in enumerate(mode_values):\n        ax.text(i, v + 0.1, str(v), ha=\"center\", fontweight=\"bold\")\n\n    # Plot 3: Success criteria verdicts\n    ax = axes[2]\n    verdict_map = {\"CONFIRMED\": 1.0, \"PARTIALLY_CONFIRMED\": 0.5, \"DISCONFIRMED\": 0.0}\n    verdict_colors = {\"CONFIRMED\": \"#4caf50\", \"PARTIALLY_CONFIRMED\": \"#ff9800\", \"DISCONFIRMED\": \"#f44336\"}\n    criteria = [v[\"criterion\"] for v in verdicts]\n    scores = [verdict_map.get(v[\"verdict\"], 0) for v in verdicts]\n    v_colors = [verdict_colors.get(v[\"verdict\"], \"#9e9e9e\") for v in verdicts]\n    ax.barh(range(len(criteria)), scores, color=v_colors, alpha=0.8, height=0.6)\n    ax.set_yticks(range(len(criteria)))\n    ax.set_yticklabels([c[:30] for c in criteria], fontsize=8)\n    ax.set_xlim(-0.1, 1.1)\n    ax.set_xlabel(\"Verdict Score\")\n    ax.set_title(\"Success Criteria Verdicts\")\n    for i, v in enumerate(verdicts):\n        ax.text(scores[i] + 0.02, i, v[\"verdict\"], va=\"center\", fontsize=7)\n\n    plt.tight_layout()\n    plt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ijk5eurr04k",
   "source": "---\n\n## Part 1 — Quick Demo (Mini Data)\n\nRuns on a 4-dataset subset (breast_cancer, diabetes, heart_statlog, sonar) with **500 bootstrap resamples** instead of 10,000 for fast execution.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "zm2ri6cc04j",
   "source": "data = load_mini()\nresults = data[\"results\"]\noblique_info = data[\"oblique_info\"]\nmetadata = data[\"metadata\"]\n\nprint(f\"Loaded {len(results)} datasets: {sorted(results.keys())}\")\nprint(f\"Methods: {sorted(set(m for ds in results.values() for m in ds.keys()))}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c86uqebjluv",
   "source": "### Module A: Bootstrap Effect Sizes (Quick — 500 resamples)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "x8hlth47ydc",
   "source": "# Quick demo: 500 resamples (original: 10,000)\nN_BOOTSTRAP = 500\nbootstrap_results = module_a_bootstrap(results, n_bootstrap=N_BOOTSTRAP)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "id6dtps37y",
   "source": "### Modules B–F: Failure Taxonomy, Split Catalog, Synergy Alignment, Verdicts, Narrative",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "4ugksordrxv",
   "source": "# Module B: Failure Taxonomy\ntaxonomy = module_b_failure_taxonomy(\n    results=results,\n    oblique_info=oblique_info,\n    metadata=metadata,\n)\n\n# Module C: Split Catalog\nsplit_catalog = module_c_split_catalog(metadata=metadata)\n\n# Module D: Synergy Alignment\nalignment_results = module_d_synergy_alignment(split_catalog=split_catalog)\n\n# Module E: Success Criteria Verdicts\nverdicts = module_e_success_verdicts(\n    bootstrap_results=bootstrap_results,\n    split_catalog=split_catalog,\n    alignment_results=alignment_results,\n    taxonomy=taxonomy,\n    oblique_info=oblique_info,\n)\n\n# Module F: Paper Narrative Synthesis\nnarrative = module_f_narrative(\n    bootstrap_results=bootstrap_results,\n    taxonomy=taxonomy,\n    split_catalog=split_catalog,\n    alignment_results=alignment_results,\n    verdicts=verdicts,\n    metadata=metadata,\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "m0d3nb646l",
   "source": "### Quick Demo Results",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "dgw5g1wrpkv",
   "source": "visualize_results(\n    bootstrap_results=bootstrap_results,\n    taxonomy=taxonomy,\n    split_catalog=split_catalog,\n    alignment_results=alignment_results,\n    verdicts=verdicts,\n    narrative=narrative,\n    title_prefix=\"[Quick Demo] \",\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ebz4d7rguvf",
   "source": "---\n\n## Full Run — Original Parameters\n\nRuns on all **12 datasets** with **10,000 bootstrap resamples** (the original configuration from `eval.py`).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0ql0vqxdlh1p",
   "source": "data = load_full()\nresults = data[\"results\"]\noblique_info = data[\"oblique_info\"]\nmetadata = data[\"metadata\"]\n\nprint(f\"Loaded {len(results)} datasets: {sorted(results.keys())}\")\nprint(f\"Methods: {sorted(set(m for ds in results.values() for m in ds.keys()))}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6y138o1fdo",
   "source": "### Module A: Bootstrap Effect Sizes (Full — 10,000 resamples)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ul22aupo8in",
   "source": "# Full run: 10,000 resamples (original parameter)\nN_BOOTSTRAP = 10_000\nbootstrap_results = module_a_bootstrap(results, n_bootstrap=N_BOOTSTRAP)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "p1l7uimzh5i",
   "source": "### Modules B–F: Full Run",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "932ip8l3lb4",
   "source": "# Module B: Failure Taxonomy\ntaxonomy = module_b_failure_taxonomy(\n    results=results,\n    oblique_info=oblique_info,\n    metadata=metadata,\n)\n\n# Module C: Split Catalog\nsplit_catalog = module_c_split_catalog(metadata=metadata)\n\n# Module D: Synergy Alignment\nalignment_results = module_d_synergy_alignment(split_catalog=split_catalog)\n\n# Module E: Success Criteria Verdicts\nverdicts = module_e_success_verdicts(\n    bootstrap_results=bootstrap_results,\n    split_catalog=split_catalog,\n    alignment_results=alignment_results,\n    taxonomy=taxonomy,\n    oblique_info=oblique_info,\n)\n\n# Module F: Paper Narrative Synthesis\nnarrative = module_f_narrative(\n    bootstrap_results=bootstrap_results,\n    taxonomy=taxonomy,\n    split_catalog=split_catalog,\n    alignment_results=alignment_results,\n    verdicts=verdicts,\n    metadata=metadata,\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "398ymgmhr0t",
   "source": "### Full Run Results",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "hxx9l8dfcq6",
   "source": "visualize_results(\n    bootstrap_results=bootstrap_results,\n    taxonomy=taxonomy,\n    split_catalog=split_catalog,\n    alignment_results=alignment_results,\n    verdicts=verdicts,\n    narrative=narrative,\n    title_prefix=\"[Full Run] \",\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}